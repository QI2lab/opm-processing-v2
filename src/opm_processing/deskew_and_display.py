"""
Deskew and display OPM data

This file is meant for quick deskew and display of qi2lab OPM results. No deconvolution and it assumes everything fits in memory.
"""

from pathlib import Path
import napari.utils
import tensorstore as ts
import napari
from napari.experimental import link_layers
from cmap import Colormap
from opm_processing.imageprocessing.opmtools import deskew, downsample_axis, deskew_shape_estimator
from opm_processing.dataio.metadata import extract_channels, find_key, extract_stage_positions
from opm_processing.dataio.ngffzarr import create_via_tensorstore, write_via_tensorstore
import json
import numpy as np
from tqdm import tqdm

def deskew_and_display(root_path: Path,z_downsample_level=2):
    """Deskew, downsample by 2x in Z, and display OPM data.
    
    This code assumes data is generated by opm-v2 GUI and the resulting data is 
    saved using OPMMirrorHandler. All revelant metadata is read from imaging files, 
    including stage transformation, camera parameters, and channels. 
    
    Parameters
    ----------
    root_path: Path
        Path to OPM pymmcoregui zarr file.
    z_downsample_level: int, default = 2
        Amount to downsample deskewed data in z.
    """
    
    # open raw datastore
    spec = {
        "driver" : "zarr",
        "kvstore" : {
            "driver" : "file",
            "path" : str(root_path)
        }
    }
    datastore = ts.open(spec).result()

    # Read metadata
    zattrs_path = root_path / Path(".zattrs")
    with open(zattrs_path, "r") as f:
        zattrs = json.load(f)

    image_mirror_step_um = float(find_key(zattrs,"image_mirror_step_um"))
    pixel_size_um = float(find_key(zattrs,"pixel_size_um"))
    opm_tilt_deg = float(find_key(zattrs,"angle_deg"))
    
    camera_offset = float(find_key(zattrs,"offset"))
    camera_conversion = float(find_key(zattrs,"e_to_ADU"))
    
    channels = extract_channels(zattrs)
    stage_positions = extract_stage_positions(zattrs)
    stage_y_flipped = True
    stage_z_flipped = True
    
    # estimate shape of one deskewed volume
    deskewed_shape = deskew_shape_estimator(
        [datastore.shape[-3],datastore.shape[-2],datastore.shape[-1]],
        theta=opm_tilt_deg,
        distance=image_mirror_step_um,
        pixel_size=pixel_size_um
    )
    datastore_shape = [
        datastore.shape[0],
        datastore.shape[1],
        datastore.shape[2],
        deskewed_shape[0]//z_downsample_level,
        deskewed_shape[1],
        deskewed_shape[2]
    ]

    # create array to hold one deskewed volume 
    deskewed = np.zeros(
        (deskewed_shape[0]//z_downsample_level,deskewed_shape[1],deskewed_shape[2]),
        dtype=np.uint16
    )
    
    # create tensorstore object for writing. This is NOT compatible with OME-NGFF!
    output_path = root_path.parents[0] / Path(str(root_path.stem)+"_deskewed.zarr")
    ts_store = create_via_tensorstore(output_path,datastore_shape)
    
    # loop over all components and stream to zarr using tensorstore
    ts_writes = []
    for t_idx in tqdm(range(datastore.shape[0]),desc="t"):
        for pos_idx in tqdm(range(datastore.shape[1]),desc="p",leave=False):
            for chan_idx in tqdm(range(datastore.shape[2]),desc="c",leave=False):
                camera_corrected_data = ((np.squeeze(datastore[t_idx,pos_idx,chan_idx,:].read().result()).astype(np.float32)-camera_offset)*camera_conversion).clip(0,2**16-1).astype(np.uint16)
                deskewed = downsample_axis(
                    deskew(
                        camera_corrected_data,
                        theta = opm_tilt_deg,
                        distance = image_mirror_step_um,
                        pixel_size = pixel_size_um,
                    ),
                    level = z_downsample_level,
                    axis = 0
                )
                
                # create future objects for async data writing
                ts_writes.append(
                    write_via_tensorstore(
                        ts_store = ts_store,
                        data = deskewed,
                        data_location = [t_idx,pos_idx,chan_idx]
                    )
                )
                
    # wait for writes to finish
    for ts_write in tqdm(ts_writes,desc='writes'):
        ts_write.result()
        
    del deskewed, ts_write, ts_store
    
    # flip y positions w.r.t. camera <-> stage orientation
    if stage_y_flipped:
        stage_y_max = np.max(stage_positions[:,1])
        for pos_idx, _ in enumerate(stage_positions):
            stage_positions[pos_idx,1] = stage_y_max - stage_positions[pos_idx,1]
            
    if stage_z_flipped:
        stage_z_max = np.max(stage_positions[:,0])
        for pos_idx, _ in enumerate(stage_positions):
            stage_positions[pos_idx,0] = stage_z_max - stage_positions[pos_idx,0]
    
    # open deskewed datastore
    spec = {
            "driver" : "zarr3",
            "kvstore" : {
                "driver" : "file",
                "path" : str(output_path)
            }
        }
    datastore = ts.open(spec).result()
    
    channel_layers = {ch: [] for ch in range(datastore.shape[2])}
    colormaps = [
        Colormap("chrisluts:bop_purple").to_napari(),
        Colormap("chrisluts:bop_blue").to_napari(),
        Colormap("chrisluts:bop_orange").to_napari(),
    ]
    viewer = napari.Viewer()
    for time_idx in range(datastore.shape[0]):
        for pos_idx in range(datastore.shape[1]):
            for chan_idx in range(datastore.shape[2]):
                layer = viewer.add_image(
                    datastore[:,pos_idx,chan_idx,:],
                    scale=[2*pixel_size_um,pixel_size_um,pixel_size_um],
                    translate=stage_positions[pos_idx],
                    name = "p"+str(pos_idx).zfill(3)+"_c"+str(chan_idx),
                    blending="additive",
                    colormap=colormaps[chan_idx],
                    contrast_limits = [50,2000]
                )
                
                channel_layers[chan_idx].append(layer)
                
    for chan_idx in range(datastore.shape[2]):
        link_layers(channel_layers[chan_idx],("contrast_limits","gamma"))
            
    napari.run()

if __name__ == "__main__":
    root_path = Path(r"G:\20250304_bulbc_brain_control\test_buffer_010.zarr")
    deskew_and_display(root_path,z_downsample_level=2)